{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_dexters_LSTM.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"cPfr34ETJvSy","colab_type":"code","outputId":"825175cb-c91e-4eec-ace0-ea672f5626bd","executionInfo":{"status":"ok","timestamp":1543546836710,"user_tz":480,"elapsed":1245,"user":{"displayName":"Shared 98999","photoUrl":"","userId":"02966646165121999534"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"dJHdiFeXKBan","colab_type":"code","outputId":"c1f36440-d15b-42fa-998b-da820615155e","executionInfo":{"status":"ok","timestamp":1543544931836,"user_tz":480,"elapsed":183373,"user":{"displayName":"Shared 98999","photoUrl":"","userId":"02966646165121999534"}},"colab":{"base_uri":"https://localhost:8080/","height":864}},"cell_type":"code","source":["\n","#Import all the required libraries\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers.advanced_activations import PReLU\n","from keras.preprocessing import sequence, text\n","from keras.layers import SpatialDropout1D\n","from keras import metrics\n","\n","#Load the training and test data\n","train = pd.read_csv('/content/drive/My Drive/web_scrap/data/train.csv')\n","test = pd.read_csv('/content/drive/My Drive/web_scrap/data/test.csv')\n","\n","y_train = train.label.values\n","y_test = test.label.values\n","\n","tk = text.Tokenizer(num_words=200000)\n","train.link_name = train.link_name.astype(str)\n","test.link_name = test.link_name.astype(str)\n","train.textdata = train.textdata.astype(str)\n","test.textdata = test.textdata.astype(str)\n","\n","max_len = 80\n","\n","tk.fit_on_texts(list(train.link_name.values) + list(train.textdata.values) + list(test.link_name.values) + list(\n","    test.textdata.values))\n","x_train_title = tk.texts_to_sequences(train.link_name.values)\n","x_train_title = sequence.pad_sequences(x_train_title, maxlen=max_len)\n","\n","x_train_textdata_01 = tk.texts_to_sequences(train.textdata.values)\n","x_train_textdata_01 = sequence.pad_sequences(x_train_textdata_01, maxlen=max_len)\n","\n","x_test_title_01 = tk.texts_to_sequences(test.link_name.values)\n","x_test_title_01 = sequence.pad_sequences(x_test_title_01, maxlen=max_len)\n","\n","x_test_textdata_02 = tk.texts_to_sequences(test.textdata.values)\n","x_test_textdata_02 = sequence.pad_sequences(x_test_textdata_02, maxlen=max_len)\n","\n","word_index = tk.word_index\n","ytrain_enc = np_utils.to_categorical(y_train)\n","\n","lstm_check_model = Sequential()\n","lstm_check_model.add(Embedding(len(word_index) + 1, 300, input_length=80, dropout=0.2),)\n","lstm_check_model.add(LSTM(300, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n","\n","lstm_check_model.add(Dense(200))\n","lstm_check_model.add(PReLU())\n","lstm_check_model.add(SpatialDropout1D(0.2))\n","\n","lstm_check_model.add(BatchNormalization())\n","\n","lstm_check_model.add(Dense(200))\n","lstm_check_model.add(PReLU())\n","lstm_check_model.add(SpatialDropout1D(0.2))\n","lstm_check_model.add(BatchNormalization())\n","\n","lstm_check_model.add(Flatten())\n","\n","lstm_check_model.add(Dense(2))\n","lstm_check_model.add(Activation('softmax'))\n","\n","\n","lstm_check_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc' ])\n","\n","\n","checkpoint = ModelCheckpoint('/content/drive/My Drive/web_scrap/data/weights.h5', monitor='val_acc', save_best_only=True, verbose=2)\n","\n","lstm_check_model.fit(x_train_title, y=ytrain_enc,\n","                 batch_size=128, epochs=20, verbose=2, validation_split=0.1,\n","                 shuffle=True, callbacks=[checkpoint])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 4167 samples, validate on 463 samples\n","Epoch 1/20\n"," - 50s - loss: 0.9584 - acc: 0.6280 - val_loss: 0.2191 - val_acc: 0.9136\n","\n","Epoch 00001: val_acc improved from -inf to 0.91361, saving model to /content/drive/My Drive/web_scrap/data/weights.h5\n","Epoch 2/20\n"," - 8s - loss: 0.1306 - acc: 0.9554 - val_loss: 0.2402 - val_acc: 0.9309\n","\n","Epoch 00002: val_acc improved from 0.91361 to 0.93089, saving model to /content/drive/My Drive/web_scrap/data/weights.h5\n","Epoch 3/20\n"," - 8s - loss: 0.0369 - acc: 0.9890 - val_loss: 0.1450 - val_acc: 0.9676\n","\n","Epoch 00003: val_acc improved from 0.93089 to 0.96760, saving model to /content/drive/My Drive/web_scrap/data/weights.h5\n","Epoch 4/20\n"," - 8s - loss: 0.0093 - acc: 0.9974 - val_loss: 0.1823 - val_acc: 0.9698\n","\n","Epoch 00004: val_acc improved from 0.96760 to 0.96976, saving model to /content/drive/My Drive/web_scrap/data/weights.h5\n","Epoch 5/20\n"," - 8s - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1549 - val_acc: 0.9719\n","\n","Epoch 00005: val_acc improved from 0.96976 to 0.97192, saving model to /content/drive/My Drive/web_scrap/data/weights.h5\n","Epoch 6/20\n"," - 9s - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1690 - val_acc: 0.9698\n","\n","Epoch 00006: val_acc did not improve from 0.97192\n","Epoch 7/20\n"," - 9s - loss: 0.0013 - acc: 0.9995 - val_loss: 0.1629 - val_acc: 0.9676\n","\n","Epoch 00007: val_acc did not improve from 0.97192\n","Epoch 8/20\n"," - 8s - loss: 4.7401e-04 - acc: 1.0000 - val_loss: 0.1648 - val_acc: 0.9676\n","\n","Epoch 00008: val_acc did not improve from 0.97192\n","Epoch 9/20\n"," - 8s - loss: 6.7646e-04 - acc: 0.9995 - val_loss: 0.1759 - val_acc: 0.9590\n","\n","Epoch 00009: val_acc did not improve from 0.97192\n","Epoch 10/20\n"," - 8s - loss: 4.3154e-04 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9654\n","\n","Epoch 00010: val_acc did not improve from 0.97192\n","Epoch 11/20\n"," - 8s - loss: 3.7776e-04 - acc: 0.9998 - val_loss: 0.2050 - val_acc: 0.9525\n","\n","Epoch 00011: val_acc did not improve from 0.97192\n","Epoch 12/20\n"],"name":"stdout"}]},{"metadata":{"id":"d1HsRmhBKJL7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}